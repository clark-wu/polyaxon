---
title: "Using Language Models with Approximate Outputs to pre-train spaCy using Polyaxon"
title_link: "Using Language Models with Approximate Outputs to pre-train spaCy using Polyaxon"
meta_title: "Using Language Models with Approximate Outputs to pre-train spaCy using Polyaxon - By matthew honnibal"
meta_description: "This repository contains experiments on spaCy's new pretrain command, which uses a ULMFit/Elmo/BERT/etc-like process for pre-training. We employ a novel trick which we term Language Modelling with Approximate Outputs (LMAO). Normally language models have to softmax (or hierarchical softmax) over the output vocabulary, which requires large hidden layers. We want to train small hidden layers, as we want spaCy to be cost-effective to run."
custom_excerpt: "This repository contains experiments on spaCy's new pretrain command, which uses a ULMFit/Elmo/BERT/etc-like process for pre-training."
featured: false
author:
  name: "Matthew Honnibal"
  slug: "matthew-honnibal"
  website: "http://spacy.io"
  twitter: "honnibal"
  github: "honnibal"
visibility: public
status: published
external: "https://github.com/honnibal/spacy-pretrain-polyaxon"
tags:
    - github
    - community
---
